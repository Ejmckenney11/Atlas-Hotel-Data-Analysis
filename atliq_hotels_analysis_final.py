# -*- coding: utf-8 -*-
"""Atliq_hotels_analysis_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ru162FgfFH3bhFe7pDLo3YGqHfnXRw4N

<h2 align="center">AtliQ Hotels Data Analysis Project<h2>

#PROJECT OVERVIEW

Atliq Grands, a distinguished player in the hospitality sector with an illustrious 20-year history, is currently facing challenges in maintaining its market share and revenue within the luxury/business hotels segment. This decline can be attributed to both strategic maneuvers by competitors and inefficiencies in managerial decision-making.

In response to these challenges, the Managing Director of Atliq Grands has identified the integration of "Business and Data Intelligence" as a pivotal strategy to regain lost ground and drive revenue growth. However, the organization lacks an in-house data analytics team capable of providing the necessary insights.

Consequently, the revenue management team has initiated plans to engage a third-party service provider to extract insights from the company's extensive historical data. This partnership aims to leverage data analytics to inform strategic decisions and optimize performance in the luxury/business hotels segment.

#OBJECTIVE

1. Data Exploration:
- Objective: Understand dataset structure and characteristics.
- Process: Load data, use Pandas for initial insights, and visualize key features.
2. Data Cleaning:
- Objective: Ensure data quality by addressing missing values and inconsistencies.
- Process: Handle missing values, standardize formats, remove duplicates, and address outliers.
3. Data Transformation:
- Objective: Prepare data for analysis by transforming variables and encoding categorical data.
- Process: Engineer features, encode categorical variables, normalize numerical data, and handle temporal data.
4. Deriving Insights from Data:
- Objective: Extract actionable insights to guide strategic decisions.
- Process: Conduct statistical analysis, visualize trends, apply machine learning, and interpret findings.
"""

import pandas as pd

"""***
### ==> 1. Data Import and Data Exploration
***

### Datasets
We have 5 csv file

   - dim_date.csv  
   - dim_hotels.csv
   - dim_rooms.csv
   - fact_aggregated_bookings
   - fact_bookings.csv

**Read bookings data in a datagrame**
"""

df_bookings = pd.read_csv('fact_bookings.csv')

"""**Explore bookings data**"""

df_bookings.head()

df_bookings.shape

df_bookings.room_category.unique()

df_bookings.booking_platform.unique()

df_bookings.booking_platform.value_counts()

df_bookings.booking_platform.value_counts().plot(kind="barh")

df_bookings.describe()

"""**Read rest of the files**"""

df_date = pd.read_csv('dim_date.csv')
df_hotels = pd.read_csv('dim_hotels.csv')
df_rooms = pd.read_csv('dim_rooms.csv')
df_agg_bookings = pd.read_csv('fact_aggregated_bookings.csv')

df_hotels.shape

df_hotels.head(3)

df_hotels.category.value_counts()

df_hotels.city.value_counts().plot(kind="bar")

df_agg_bookings.head(3)

df_agg_bookings.property_id.unique()

df_agg_bookings.groupby("property_id")["successful_bookings"].sum()

df_agg_bookings[df_agg_bookings["successful_bookings"] > df_agg_bookings["capacity"]]

df_agg_bookings.capacity.max()

df_agg_bookings[df_agg_bookings.capacity==df_agg_bookings.capacity.max()]

"""#NOTES

The line of code

```
# df_agg_bookings[df_agg_bookings.capacity==df_agg_bookings.capacity.max()]
```

- filters the dataframe df_agg_bookings to only include rows where the value in the capacity column is equal to the maximum value in the capacity column.
- In other words, it selects the rows with the highest capacity from the dataframe.
- This is useful for tasks such as finding the vehicles with the largest capacity or identifying the most popular room sizes in a hotel.

***
### ==> 2. Data Cleaning
***
"""

df_bookings.describe()

"""**(1) Clean invalid guests**"""

df_bookings[df_bookings.no_guests<=0]

"""As you can see above, number of guests having less than zero value represents data error. We can ignore these records."""

df_bookings = df_bookings[df_bookings.no_guests>0]

# so We used this function to filter out any data where the number of guests
# was negative. so anything above zero we take as a legitamite value in our data
# set. Our reason for getting rid of the outliers was because the data set is
# 134590 bookings. getting rid of 12 outliers will have no affect on our data

df_bookings.shape

"""**(2) Outlier removal in revenue generated**"""

df_bookings.revenue_generated.min(), df_bookings.revenue_generated.max()

# no hotel room cost 28 million lol. this is an outlier an needs fixed

df_bookings.revenue_generated.mean(), df_bookings.revenue_generated.median()

avg, std = df_bookings.revenue_generated.mean(), df_bookings.revenue_generated.std()

avg, std

higher_limit = avg + 3*std
higher_limit

lower_limit = avg - 3*std
lower_limit

df_bookings[df_bookings.revenue_generated<=0]

# no revenue below 0

df_bookings[df_bookings.revenue_generated>higher_limit]

# values higher than the higher limit. "Outliers"
# need to get rid of these values

df_bookings = df_bookings[df_bookings.revenue_generated<=higher_limit]
df_bookings.shape

# clean them using a reverse condition

df_bookings.revenue_realized.describe()

higher_limit = df_bookings.revenue_realized.mean() + 3*df_bookings.revenue_realized.std()
higher_limit

df_bookings[df_bookings.revenue_realized>higher_limit]

# there is 1299 rows that are greater than the higher limit so we have to take this
# information since it is signiftcant and possibly change our std from a multiple of
# 3. if we use our common sense we realize RT4 which is the presidential suite is
# going to cost the most. so its reasonable to assume that we need to consider that
# when trying to find outliers in our data

df_rooms

"""One observation we can have in above dataframe is that all rooms are RT4 which means presidential suit. Now since RT4 is a luxurious room it is likely their rent will be higher. To make a fair analysis, we need to do data analysis only on RT4 room types"""

df_bookings[df_bookings.room_category=="RT4"].revenue_realized.describe()

# we are looking at just RT4

# mean + 3*standard deviation
23439+3*9048

# So because the higher limit came out to be 50583, if we go back and see our data
# the maximum generated revenue from a suite is 45220 which is less than our higher limit
# of suites for just RT4. So therefore we have no outliers associated with the
# revenue_realized column

"""Here higher limit comes to be 50583 and in our dataframe above we can see that max value for revenue realized is 45220. Hence we can conclude that there is no outlier and we don't need to do any data cleaning on this particular column"""

df_bookings[df_bookings.booking_id=="May012216558RT213"]

df_bookings.isnull().sum()

# Isnull function gives you true or false on whethere the column
# is Na

# okay to have Na values in ratings given

"""Total values in our dataframe is 134576. Out of that 77899 rows has null rating. Since there are many rows with null rating, we should not filter these values. Also we should not replace this rating with a median or mean rating etc

In aggregate bookings we are finding the columns that have null values. And are filling these null values with the median capacity of each room
"""

df_agg_bookings.isnull().sum()

df_agg_bookings[df_agg_bookings.capacity.isna()]

df_agg_bookings.capacity.fillna(df_agg_bookings.capacity.median(), inplace=True)

df_agg_bookings.loc[[8,14]]

"""In aggregate bookings we find out records that have successful_bookings value greater than capacity ane Filter those records"""

df_agg_bookings[df_agg_bookings['successful_bookings'] > df_agg_bookings['capacity']]

# This shows the where successful bookings value is greater than the capacity

df_agg_bookings.shape

df_agg_bookings = df_agg_bookings[df_agg_bookings.successful_bookings<=df_agg_bookings.capacity]
df_agg_bookings.shape

# We reverse engineer the problem by filtering out the successful books greater than
# capacity and only shows the bookings that are less than or equal to capactiy

"""***
### ==> 3. Data Transformation
***

**Creating occupancy percentage column**
"""

df_agg_bookings.head(3)

df_agg_bookings['occ_pct'] = df_agg_bookings.apply(lambda row: row['successful_bookings']/row['capacity'], axis=1)

"""This code adds a new column named 'occ_pct' to the df_agg_bookings DataFrame. It calculates the occupancy percentage for each row by dividing the 'successful_bookings' by the 'capacity'. This calculation is done row-wise using the apply function with a lambda function along the rows (axis=1)."""

new_col = df_agg_bookings.apply(lambda row: row['successful_bookings']/row['capacity'], axis=1)
df_agg_bookings = df_agg_bookings.assign(occ_pct=new_col.values)
df_agg_bookings.head(3)

"""This code also adds a new column named 'occ_pct' to the df_agg_bookings DataFrame. However, it uses an alternative method using the assign method. It first calculates the occupancy percentage for each row similarly to the previous method. Then, it assigns this calculated column to the DataFrame using .assign().

Converting it to a percentage value
"""

df_agg_bookings['occ_pct'] = df_agg_bookings['occ_pct'].apply(lambda x: round(x*100, 2))
df_agg_bookings.head(3)

df_bookings.head()

df_agg_bookings.info()

"""Various types of Data Transformation Tactics we will be using for this dataset

1. Creating new columns
1. Normalization
1. Merging data
1. Aggregation

***
### ==> 4. Insights Generation
***

**1. What is an average occupancy rate in each of the room categories?**
"""

df_agg_bookings.head(3)

df_agg_bookings.groupby("room_category")["occ_pct"].mean()

df_rooms

"""Matching RT1, RT2 etc. with room categories such as Standard, Premium, Elite etc along with average occupancy percentage"""

df = pd.merge(df_agg_bookings, df_rooms, left_on="room_category", right_on="room_id")
df.head(4)

df.drop("room_id",axis=1, inplace=True)
df.head(4)

# Inplace means to modify the Data Frame, very important
# it will not updat the same dataframe if you do not

df.groupby("room_class")["occ_pct"].mean()

df[df.room_class=="Standard"].occ_pct.mean()

"""**2. Print average occupancy rate per city**"""

df_hotels.head(3)

df = pd.merge(df, df_hotels, on="property_id")
df.head(3)

# Overall, this code snippet merges two DataFrames (df and df_hotels) based on the
# common column "property_id", allowing for the combination of booking/room data
# with hotel/property information.

df.rename(columns={'city_y': 'city'}, inplace=True)
df

df.groupby("city")["occ_pct"].mean()

"""**3. When was the occupancy better? Weekday or Weekend?**"""

df_date.head(3)

df = pd.merge(df, df_date, left_on="check_in_date", right_on="date")
df.head(3)

df.rename(columns={'mmm yy': 'month_year'}, inplace=True)
df

df.groupby("day_type")["occ_pct"].mean().round(2)

"""**4: In the month of June, This is the occupancy for different cities**"""

df_june_22 = df[df["month_year"]=="Jun 22"]
df_june_22.head(4)

# Filtering our data frame specifically for June
# for the occupancy rate

df_june_22.groupby('city')['occ_pct'].mean().round(2).sort_values(ascending=False)

df_june_22.groupby('city')['occ_pct'].mean().round(2).sort_values(ascending=False).plot(kind="bar")

"""**5: There is new data for the month of august so we Append that to existing data**"""

df_august = pd.read_csv("new_data_august.csv")
df_august.head(3)

df_august.columns

df.columns

df_august.shape

df.shape

latest_df = pd.concat([df, df_august], ignore_index = True, axis = 0)
latest_df.tail(10)

latest_df.shape

"""Check this post for codebasics resume project challange winner entry: https://www.linkedin.com/posts/ashishbabaria_codebasicsresumeprojectchallenge-data-powerbi-activity-6977940034414886914-dmoJ?utm_source=share&utm_medium=member_desktop

**6. Print revenue realized per city**
"""

df_bookings.head()

df_hotels.head(3)

df_bookings_all = pd.merge(df_bookings, df_hotels, on="property_id")
df_bookings_all.head(3)

df_bookings_all.groupby("city")["revenue_realized"].sum()

"""**7. Print month by month revenue**"""

df_bookings_all.head(3)

df_date["mmm yy"].unique()

df_date.head(3)

df_bookings_all.info()

df_date["date"] = pd.to_datetime(df_date["date"])
df_date.head(3)

df_date.info()

df_bookings_all["check_in_date"].unique()

def parse_date(date_str):
    try:
        return pd.to_datetime(date_str, format="%m/%d/%Y")
    except ValueError:
        return pd.to_datetime(date_str, format="%d-%m-%y")

df_bookings_all["check_in_date"] = df_bookings_all["check_in_date"].apply(parse_date)
df_bookings_all.head(4)

"""#NOTES

###Summary of the Solution:

- We encountered an issue where the date formats in the "check_in_date" column were inconsistent, leading to parsing errors.
To address this, we defined a custom parsing function (parse_date) that attempts to parse the date string using two different formats: "%m/%d/%Y" and "%d-%m-%y".
By applying this custom function to each date string in the DataFrame, we successfully parsed the dates, handling both formats correctly.

###Prevention:

- To prevent similar issues in the future, it's essential to ensure consistency in date formats across the dataset. Standardizing the date format during data collection or preprocessing can help avoid parsing errors. Additionally, specifying a consistent date format when reading data into pandas DataFrame can be helpful. If multiple date formats are expected, implementing robust error handling, as demonstrated in the provided solution, can handle parsing errors gracefully.
"""

df_bookings_all.info()

df_bookings_all = pd.merge(df_bookings_all, df_date, left_on="check_in_date", right_on="date")
df_bookings_all.head(3)

df_bookings_all.groupby("mmm yy")["revenue_realized"].sum()

"""**Exercise-1. Print revenue realized per hotel type**"""

df_bookings_all["property_name"].unique()

rr_per_hotel = df_bookings_all.groupby("property_name")["revenue_realized"].sum()

rr_per_hotel

"""**average rating per city**"""

avg_rating_per_city = df_bookings_all.groupby("city")["ratings_given"].mean()

avg_rating_per_city = avg_rating_per_city.sort_values(ascending=True)
avg_rating_per_city

"""**Showing a pie chart of revenue realized per booking platform**"""

df_bookings_all = df_bookings_all.groupby("booking_platform")["revenue_realized"].sum().sort_values(ascending=True).plot(kind="pie")